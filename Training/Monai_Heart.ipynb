{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "879b0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from monai.networks.nets import resnet18  # Import resnet18 from MONAI\n",
    "from fastai.learner import Learner\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.callback.all import SaveModelCallback, EarlyStoppingCallback\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eae4bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"heart_disease_model.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "869ae9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPYDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for loading 3D medical imaging data from .npy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, image_column_name, label_column_name, custom_transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with optional custom transforms.\n",
    "        \n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe containing file paths and labels\n",
    "            image_column_name (str): Column name for image file paths\n",
    "            label_column_name (str): Column name for labels\n",
    "            custom_transform (callable, optional): Optional custom transform pipeline\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_column_name = image_column_name\n",
    "        self.label_column_name = label_column_name\n",
    "        \n",
    "        # Default transforms \n",
    "        default_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.Resize((112, 112)),  # Med3D default size\n",
    "        ])\n",
    "        \n",
    "        # Use custom transform if provided, otherwise use default\n",
    "        self.transform = custom_transform if custom_transform is not None else default_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load and preprocess a single sample.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (processed image, label)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            npy_path = self.dataframe[self.image_column_name].iloc[idx]\n",
    "            label = self.dataframe[self.label_column_name].iloc[idx]\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            image = np.load(npy_path)[:, :, :, 0]  # 2nd axis view\n",
    "            image = image[17:33, :, :]  # Select frames 17 to 32\n",
    "            \n",
    "            # Convert to tensor and add channel dimension\n",
    "            image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
    "            \n",
    "            # Apply transforms\n",
    "            image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image at index {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class HeartDiseaseModel:\n",
    "    \"\"\"\n",
    "    Comprehensive model for heart disease classification using 3D medical imaging.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the model with comprehensive configuration.\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Configuration dictionary with model parameters\n",
    "        \"\"\"\n",
    "        # Validate and set configuration\n",
    "        self.config = self._validate_config(config)\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Prepare data and model\n",
    "        self._prepare_data()\n",
    "        self._prepare_model()\n",
    "\n",
    "    def _validate_config(self, config):\n",
    "        \"\"\"\n",
    "        Validate and set default values for configuration.\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Input configuration\n",
    "        \n",
    "        Returns:\n",
    "            dict: Validated configuration with defaults\n",
    "        \"\"\"\n",
    "        default_config = {\n",
    "            'train_dataframe_path': None,\n",
    "            'test_dataframe_path': None,\n",
    "            'image_column_name': 'FilePath',\n",
    "            'label_column_name': 'CAD',\n",
    "            'pretrained_weights_path': None,\n",
    "            'batch_size': 8,\n",
    "            'split_ratio': 0.85,\n",
    "            'model_name': 'heart_disease_model_resnet18',\n",
    "            'learning_rate': 1e-5,\n",
    "            'epochs': 50,\n",
    "            'early_stopping_patience': 20,\n",
    "            'weight_decay': 1e-4\n",
    "        }\n",
    "        \n",
    "        # Update defaults with provided config\n",
    "        default_config.update(config)\n",
    "        \n",
    "        # Validate required paths\n",
    "        required_paths = [\n",
    "            'train_dataframe_path', \n",
    "            'test_dataframe_path', \n",
    "            'pretrained_weights_path'\n",
    "        ]\n",
    "        for path in required_paths:\n",
    "            if not default_config[path] or not os.path.exists(default_config[path]):\n",
    "                raise ValueError(f\"Invalid path for {path}: {default_config[path]}\")\n",
    "        \n",
    "        return default_config\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        \"\"\"Prepare training, validation, and test datasets and dataloaders.\"\"\"\n",
    "        try:\n",
    "            # Load dataframes\n",
    "            train_df = pd.read_csv(self.config['train_dataframe_path'])\n",
    "            test_df = pd.read_csv(self.config['test_dataframe_path'])\n",
    "            \n",
    "            # Create dataset\n",
    "            dataset = NPYDataset(\n",
    "                train_df, \n",
    "                self.config['image_column_name'], \n",
    "                self.config['label_column_name']\n",
    "            )\n",
    "            \n",
    "            # Split train and validation\n",
    "            train_size = int(self.config['split_ratio'] * len(dataset))\n",
    "            val_size = len(dataset) - train_size\n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n",
    "                dataset, [train_size, val_size]\n",
    "            )\n",
    "            \n",
    "            # Create dataloaders\n",
    "            self.train_loader = DataLoader(\n",
    "                self.train_dataset, \n",
    "                batch_size=self.config['batch_size'], \n",
    "                shuffle=True, \n",
    "                num_workers=8\n",
    "            )\n",
    "            self.val_loader = DataLoader(\n",
    "                self.val_dataset, \n",
    "                batch_size=self.config['batch_size'], \n",
    "                shuffle=False, \n",
    "                num_workers=8\n",
    "            )\n",
    "            \n",
    "            # Prepare test data\n",
    "            self.test_dataset = NPYDataset(\n",
    "                test_df, \n",
    "                self.config['image_column_name'], \n",
    "                self.config['label_column_name']\n",
    "            )\n",
    "            self.test_loader = DataLoader(\n",
    "                self.test_dataset, \n",
    "                batch_size=self.config['batch_size'], \n",
    "                shuffle=False, \n",
    "                num_workers=8\n",
    "            )\n",
    "            \n",
    "            self.logger.info(\"Data preparation completed successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in data preparation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _prepare_model(self):\n",
    "        \"\"\"Prepare the model, loss function, and learning rate scheduler.\"\"\"\n",
    "        try:\n",
    "            # Initialize model with ResNet18\n",
    "            self.model = resnet18(\n",
    "                spatial_dims=3, \n",
    "                n_input_channels=1,  # Assuming grayscale input\n",
    "                num_classes=2  # Binary classification\n",
    "            )\n",
    "            \n",
    "            # Load pretrained weights\n",
    "            self.logger.info(\"Loading pretrained weights...\")\n",
    "            state_dict = torch.load(self.config['pretrained_weights_path'])\n",
    "            self.model.load_state_dict(state_dict, strict=False)\n",
    "            \n",
    "            # Parallel processing and device transfer\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "            self.model.to(self.device)\n",
    "            \n",
    "            # Create FastAI learner\n",
    "            self.dls = DataLoaders(self.train_loader, self.val_loader)\n",
    "            self.learn = Learner(\n",
    "                self.dls,\n",
    "                self.model,\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                wd=self.config['weight_decay'],\n",
    "                cbs=[\n",
    "                    SaveModelCallback(\n",
    "                        fname=self.config['model_name'], \n",
    "                        monitor='valid_loss'\n",
    "                    ),\n",
    "                    EarlyStoppingCallback(\n",
    "                        monitor='valid_loss', \n",
    "                        patience=self.config['early_stopping_patience']\n",
    "                    )\n",
    "                ]\n",
    "            ).to_fp16()\n",
    "            \n",
    "            self.logger.info(\"Model preparation completed successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in model preparation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model with configured hyperparameters.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Starting model training...\")\n",
    "            self.learn.fine_tune(\n",
    "                self.config['epochs'], \n",
    "                base_lr=self.config['learning_rate']\n",
    "            )\n",
    "            self.logger.info(\"Model training completed successfully\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during model training: {e}\")\n",
    "            raise\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate model performance on validation and test datasets.\"\"\"\n",
    "        try:\n",
    "            def evaluate_dataset(loader, dataset_name):\n",
    "                self.learn.validate()\n",
    "                preds, targs = self._get_predictions(loader)\n",
    "                \n",
    "                # Classification report\n",
    "                report = classification_report(\n",
    "                    targs, preds, \n",
    "                    target_names=['No CAD', 'CAD']\n",
    "                )\n",
    "                self.logger.info(f\"Classification Report for {dataset_name} Data:\\n{report}\")\n",
    "                \n",
    "                # Confusion matrix\n",
    "                cm = confusion_matrix(targs, preds)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(\n",
    "                    cm, \n",
    "                    annot=True, \n",
    "                    fmt='d', \n",
    "                    cmap='Blues', \n",
    "                    xticklabels=['No CAD', 'CAD'], \n",
    "                    yticklabels=['No CAD', 'CAD']\n",
    "                )\n",
    "                plt.xlabel('Predicted')\n",
    "                plt.ylabel('True')\n",
    "                plt.title(f'Confusion Matrix for {dataset_name} Data')\n",
    "                plt.savefig(f'{dataset_name.lower()}_confusion_matrix.png')\n",
    "                plt.close()\n",
    "            \n",
    "            # Evaluate validation and test datasets\n",
    "            evaluate_dataset(self.val_loader, \"Validation\")\n",
    "            evaluate_dataset(self.test_loader, \"Test\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during model evaluation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _get_predictions(self, data_loader):\n",
    "        \"\"\"\n",
    "        Generate predictions for a given dataloader.\n",
    "        \"\"\"\n",
    "        preds, targs = [], []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                images, labels = batch\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                preds.extend(predicted.cpu().numpy())\n",
    "                targs.extend(labels.cpu().numpy())\n",
    "        \n",
    "        return preds, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa056a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 16:07:42,257 - HeartDiseaseModel - INFO - Using device: cuda\n",
      "2024-12-01 16:07:43,129 - HeartDiseaseModel - INFO - Data preparation completed successfully\n",
      "2024-12-01 16:07:43,919 - HeartDiseaseModel - INFO - Loading pretrained weights...\n",
      "/tmp/ipykernel_1766696/2779544242.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(self.config['pretrained_weights_path'])\n",
      "2024-12-01 16:07:44,476 - HeartDiseaseModel - INFO - Model preparation completed successfully\n",
      "2024-12-01 16:07:44,478 - HeartDiseaseModel - INFO - Starting model training...\n",
      "/work/07880/devansh/anaconda3/envs/pyt_env/lib/python3.8/site-packages/fastai/callback/fp16.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
      "/work/07880/devansh/anaconda3/envs/pyt_env/lib/python3.8/site-packages/fastai/callback/fp16.py:45: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.679124</td>\n",
       "      <td>0.654153</td>\n",
       "      <td>0.613050</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6541532874107361.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/07880/devansh/anaconda3/envs/pyt_env/lib/python3.8/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>0.656159</td>\n",
       "      <td>0.606222</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659614</td>\n",
       "      <td>0.642117</td>\n",
       "      <td>0.638088</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.668766</td>\n",
       "      <td>0.644181</td>\n",
       "      <td>0.632777</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.667710</td>\n",
       "      <td>0.645368</td>\n",
       "      <td>0.630501</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.660385</td>\n",
       "      <td>0.640198</td>\n",
       "      <td>0.638847</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.670080</td>\n",
       "      <td>0.649243</td>\n",
       "      <td>0.630501</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.640185</td>\n",
       "      <td>0.638088</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.650495</td>\n",
       "      <td>0.645700</td>\n",
       "      <td>0.637329</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.648227</td>\n",
       "      <td>0.643213</td>\n",
       "      <td>0.638847</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.639713</td>\n",
       "      <td>0.655661</td>\n",
       "      <td>0.628225</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.643407</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.631260</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.643990</td>\n",
       "      <td>0.665613</td>\n",
       "      <td>0.623672</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.640279</td>\n",
       "      <td>0.684561</td>\n",
       "      <td>0.600152</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.644587</td>\n",
       "      <td>0.652575</td>\n",
       "      <td>0.628225</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.653956</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.635812</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.636385</td>\n",
       "      <td>0.662220</td>\n",
       "      <td>0.630501</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.652451</td>\n",
       "      <td>0.645845</td>\n",
       "      <td>0.622913</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.658248</td>\n",
       "      <td>0.635763</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.634017</td>\n",
       "      <td>0.632799</td>\n",
       "      <td>0.654021</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.639913</td>\n",
       "      <td>0.633973</td>\n",
       "      <td>0.642640</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.627788</td>\n",
       "      <td>0.646351</td>\n",
       "      <td>0.635812</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.630540</td>\n",
       "      <td>0.630102</td>\n",
       "      <td>0.662367</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.625009</td>\n",
       "      <td>0.630335</td>\n",
       "      <td>0.654780</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.635082</td>\n",
       "      <td>0.658949</td>\n",
       "      <td>0.632018</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.617674</td>\n",
       "      <td>0.622615</td>\n",
       "      <td>0.656297</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.639459</td>\n",
       "      <td>0.652938</td>\n",
       "      <td>0.635053</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.609350</td>\n",
       "      <td>0.623555</td>\n",
       "      <td>0.641882</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.631773</td>\n",
       "      <td>0.628502</td>\n",
       "      <td>0.643399</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.614488</td>\n",
       "      <td>0.623383</td>\n",
       "      <td>0.650228</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.609976</td>\n",
       "      <td>0.627932</td>\n",
       "      <td>0.656297</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.632170</td>\n",
       "      <td>0.626119</td>\n",
       "      <td>0.655539</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.633719</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>0.653262</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.627706</td>\n",
       "      <td>0.620843</td>\n",
       "      <td>0.650986</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.613131</td>\n",
       "      <td>0.616802</td>\n",
       "      <td>0.663885</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.637612</td>\n",
       "      <td>0.610052</td>\n",
       "      <td>0.663126</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.612893</td>\n",
       "      <td>0.624615</td>\n",
       "      <td>0.657815</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.628237</td>\n",
       "      <td>0.608462</td>\n",
       "      <td>0.665402</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.616254</td>\n",
       "      <td>0.619171</td>\n",
       "      <td>0.647193</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.619772</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.659332</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.600691</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.650228</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.609104</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.668437</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.603486</td>\n",
       "      <td>0.616010</td>\n",
       "      <td>0.664643</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.597217</td>\n",
       "      <td>0.619549</td>\n",
       "      <td>0.656297</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.582809</td>\n",
       "      <td>0.614462</td>\n",
       "      <td>0.672231</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.619398</td>\n",
       "      <td>0.610967</td>\n",
       "      <td>0.670713</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.614784</td>\n",
       "      <td>0.615046</td>\n",
       "      <td>0.658574</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.587298</td>\n",
       "      <td>0.612770</td>\n",
       "      <td>0.667678</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.598484</td>\n",
       "      <td>0.617949</td>\n",
       "      <td>0.656297</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.583715</td>\n",
       "      <td>0.611336</td>\n",
       "      <td>0.666161</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.598185</td>\n",
       "      <td>0.615328</td>\n",
       "      <td>0.663126</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6561588644981384.\n",
      "Better model found at epoch 1 with valid_loss value: 0.6421169638633728.\n",
      "Better model found at epoch 4 with valid_loss value: 0.6401976346969604.\n",
      "Better model found at epoch 6 with valid_loss value: 0.6401851773262024.\n",
      "Better model found at epoch 17 with valid_loss value: 0.6357626914978027.\n",
      "Better model found at epoch 18 with valid_loss value: 0.6327994465827942.\n",
      "Better model found at epoch 21 with valid_loss value: 0.6301022171974182.\n",
      "Better model found at epoch 24 with valid_loss value: 0.6226145029067993.\n",
      "Better model found at epoch 32 with valid_loss value: 0.6208434104919434.\n",
      "Better model found at epoch 33 with valid_loss value: 0.6168020963668823.\n",
      "Better model found at epoch 34 with valid_loss value: 0.6100522875785828.\n",
      "Better model found at epoch 36 with valid_loss value: 0.6084619164466858.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 16:55:17,925 - HeartDiseaseModel - INFO - Model training completed successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='121' class='' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      73.33% [121/165 00:03&lt;00:01 0.5982]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function for the heart disease classification model.\"\"\"\n",
    "    try:\n",
    "        config = {\n",
    "            'train_dataframe_path': 'Final_Datasets/train_resnet_heart.csv',\n",
    "            'test_dataframe_path': 'Final_Datasets/test_data_incidence.csv',\n",
    "            'pretrained_weights_path': '../Med3D/resnet_18_23dataset.pth',  # Path to ResNet18 weights\n",
    "            'model_name': 'heart_ch0_3channel_MONAI_resnet18',\n",
    "            'epochs': 50,\n",
    "            'learning_rate': 1e-5\n",
    "        }\n",
    "        \n",
    "        model = HeartDiseaseModel(config)\n",
    "        model.train()\n",
    "        model.evaluate()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b5448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "pyt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
